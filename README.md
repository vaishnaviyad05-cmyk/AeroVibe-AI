# AeroVibe-AI ðŸ›¸

AeroVibe-AI is a gesture-based interaction system that I built to explore the intersection of **Computer Vision** and **Human-Computer Interaction (HCI)**. The goal was to create a way to control system functions without ever touching a mouse or keyboard.

## ðŸ’¡ The Vision
The core idea behind AeroVibe is "Natural UI." Instead of memorizing complex hotkeys, the system uses the natural movement of the human hand to bridge the gap between the physical and digital worlds.

## ðŸ›  Built With
* **Python** - Core logic
* **MediaPipe** - Real-time hand landmark detection (21-point tracking)
* **OpenCV** - Image processing and camera handling
* **PyAutoGUI** - System-level interaction
* **Tkinter** - Developing the GUI overlay

## ðŸŒŸ Key Capabilities
* **Dynamic Tracking:** High-speed tracking that works even in varying lighting conditions.
* **Smart UI:** A dedicated control panel to toggle AI features on and off.
* **Low Latency:** Optimized frame processing to ensure the cursor/commands feel responsive.

## ðŸš€ Getting Started

### Prerequisites
Ensure you have Python 3.8+ installed.

### Setup
1. Clone this repo:
   ```bash
   git clone [https://github.com/vaishnaviyad05-cmyk/AeroVibe-AI.git](https://github.com/vaishnaviyad05-cmyk/AeroVibe-AI.git)
   

